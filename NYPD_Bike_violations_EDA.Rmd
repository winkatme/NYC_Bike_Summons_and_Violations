---
title: "R Notebook"
output: 
  github_document:
    html_preview: FALSE
---

```{r libraries, message=FALSE}
library(knitr)
knitr::opts_chunk$set(message = FALSE)
# options(digits = 7)
library(rmarkdown)
library(fpp3)
library(readxl)
library(httr)
library(glue)
# install.packages("corrr")
library(corrr)
library(slider)
library(forcats)
# devtools::install_github('smin95/smplot2', force = TRUE)
library(smplot2)
# install.packages('sf')
library(sf)
# install.packages('Rcpp')
library(Rcpp)
# install.packages('mapview')
library(mapview)
library(janitor)
#install.packages('styler')
library(styler)
```

# Import Data & Create tsibble

```{r import-and-tsibble, include=FALSE}
df <- readr::read_csv("df_bike_violations_2023-07-09.csv")

df <- df |>
  mutate(violation_code = as.factor(violation_code)) |>
  mutate(veh_category = as.factor(veh_category)) |>
  mutate(city_nm = as.factor(city_nm)) |>
  mutate(rpt_owning_cmd = as.factor(rpt_owning_cmd)) |>
  mutate(violation_date = as.POSIXct(violation_date))


# create a daily data tsibble
ts_daily_total <- df |>
  mutate(violation_date = as_date(violation_date)) |>
  group_by(violation_date, daily_total_cyclists) |>
  summarize(daily_total_violations = sum(n())) |>
  ungroup() |>
  as_tsibble(index = violation_date)
```

## Clean daily tsibble

```{r clean}
# check for missing dates  # ans: 24
ts_daily_total |>
  # filter(is.na(daily_total_cyclists)) |>
  count_gaps()

# are the days missing from df_counts?  # ans: no.
# df_counts |>
#  filter(is.na(daily_total))



# fill gaps dates and re-join with df_counts data, so that gapped dates now have total cyclsits. Replace violation na's with 0s.

# import df_counts:
path2 <- "https://www.dropbox.com/s/oaklaldm8td9wem/Bicycle_Counts.csv?dl=1"
df_counts <- read.csv(path2)

df_counts <- df_counts |>
  filter(id %in% bike_counter_ids_no_dupes) |> 
  mutate(date = mdy_hms(date)) |>
  group_by(date(date)) |>
  mutate(daily_total = sum(counts)) |>
  ungroup() |>
  group_by(yearweek(date)) |>
  mutate(weekly_total = sum(counts)) |>
  ungroup() |>
  arrange(date) |>
  select(-c("date(date)", "yearweek(date)")) |>
  mutate(date = date(date)) |>
  select(-c(countid, id, status))

ts_daily_total <- ts_daily_total |>
  fill_gaps() |>
  select(-daily_total_cyclists) |>
  mutate(date = violation_date) |>
  left_join(y = df_counts, by = "date", multiple = "any") |>
  rename(daily_total_cyclists = daily_total) |>
  select(-c("date", "counts", "weekly_total")) |>
  mutate_at("daily_total_violations", ~ replace_na(., 0))


# double check for na's:
ts_daily_total |>
  filter(is.na(daily_total_cyclists))

# double check for date gaps:
ts_daily_total |>
  count_gaps()


ts_daily_total
```

## Create monthly data tsibble

```{r monthly-tsibble}
# create a monthly data tsibble from cleaned daily tsibble
ts_monthly_total <- ts_daily_total |>
  index_by(yearmonth(violation_date)) |>
  summarize(across(c("daily_total_violations", "daily_total_cyclists"), ~ sum(.x, na.rm = TRUE))) |>
  rename(monthly_total_cyclists = daily_total_cyclists) |>
  rename(monthly_total_violations = daily_total_violations) |>
  rename(violation_date = "yearmonth(violation_date)")
```

# EDA: General

## What's the date range for the data?

```{r}
date(range(df$violation_date))
```

## Which dates had the highest number of riders, and how many?

```{r top-10-daily-total-cyclist-days}
df |>
  mutate(violation_date = date(violation_date)) |>
  arrange(desc(daily_total_cyclists)) |>
  distinct(violation_date, daily_total_cyclists) |>
  slice(1:10) |>
  kable(caption = "Top 10 busiest cyclist days", align = "c")

# takeaway: no particular trends, but mostly late summer / early autumn.  4 from September 2022.
```

## Which dates had the highest number of violations, and how many violations?

```{r}
df |>
  mutate(violation_date = date(violation_date)) |>
  summarize(
    daily_total_violations = sum(n()),
    .by = violation_date
  ) |>
  arrange(desc(daily_total_violations)) |>
  slice(1:10) |>
  kable(caption = "Top 10 busiest violation days", align = "c")


# mostly warmer days in 2018 and 2019, pre-pandemic
```

# EDA: Bike Counters

## Geoplot: bike counters

```{r geoplot-bike-counters}

mapview(na.omit(df_bicycle_counters_boroughs), xcol = "longitude", ycol = "latitude", crs = 4269, grid = FALSE)
```

### Bike counters used per year

```{r}
df_counts_raw |> 
  mutate(date = mdy_hms(date)) |> 
  mutate(id = as.factor(id)) |> 
  group_by(year=year(date)) |> 
  distinct(id) |> 
  summarise(n=n()) 
# looks like max per year is 20.  so not all  are used at once.
  

# lets look at the ones used in 2023 and their counts
df_counts_raw |> 
  mutate(date = mdy_hms(date)) |> 
  mutate(date=year(date)) |> 
  filter(date=='2023') |> 
  mutate(id=as.factor(id)) |> 
  summarize(sum=sum(counts), .by=id) |> 
  arrange(sum)
  
#brooklyn bridge has some dupes.
  
df_counts_raw  
```


## Which bike counter counted the most cyclists in 2022? during the busiest months?

```{r}
df_counts_raw |> 
  mutate(date = date(mdy_hms(date))) |> 
  filter(year(date)==2022) |> 
  arrange(date) |> 
  group_by(id) |> 
  mutate(sum = sum(counts)) |> 
  ungroup() |> 
  distinct(id, .keep_all=TRUE) |> 
  arrange(desc(sum))

# 1. 100009427 with 1964902 counts: wburg side of wburg bridge.
# 2. 100009428 with 1818163 counts: Queens side of Queensboro
# 3. 100047029 with 1584788: Manhattan side of Manhattan bridge 1584788
# 4. 100062893, same as above
# 5. 100010019 with 1066870: Kent ave in Wburg
# 6. 300020241 with 1002070: Manhattan side of Brookly bridge

# geoplot biggest of 2022
df_bicycle_counters |> 
  filter(id==300020241
         ) |> 
  mapview(xcol = "longitude", ycol = "latitude", crs = 4269, grid = FALSE)  

```

### To do: which bike counter counted the most bikes during the busiest month?

```{r}

```



## To Do: Does most common bike counter have higher violations?

```{r}
# not sure how to answer this with the data with the data.



```



# EDA: Violation Codes

## How many different violations were handed out to cyclist?

```{r}
length(fct_unique(df$violation_code))
# ans: 183
```

## How many total violations were handed out to cyclists?

```{r}
length(df$violation_code)

# ans: 122509
```

## What were the most popular violations?

```{r 10-most-popular-violations-table, message=FALSE}
df |>
  mutate(violation_date = date(violation_date)) |>
  summarize(
    total = sum(n()),
    .by = c(violation_code, description)
  ) |>
  arrange(desc(total)) |>
  mutate(percent = 100 * round(total / sum(total), 3)) |>
  slice(1:10) |>
  kable()

# takewaways:  44% were for failing to stop at red light.

# note:  12332: ATTACHING SELF TO MOVING MOTOR VEHICLE a/k/a, the Marty McFly rule
```

### Unique violation: code 12332: Marty McFly

```{r}
df |> 
  filter(violation_code==12332) |> 
  select(violation_code, violation_date, description)

df |> 
  filter(violation_code==12332) |> 
  mapview(xcol = "longitude", ycol = "latitude", crs = 4269, grid = FALSE)


```

## Geocode: Violations location clusters

```{r}
# view geomap of violations, post-covid
# wasnt able to use dplyr due to missing values.
df_fct_lump_post_covid <- df |>
  mutate(fct_lump = fct_lump(f = df$violation_code, n = 9)) |>
  mutate(date = date(violation_date)) |>
  filter(date >= "2020-04-01")


mapview(na.omit(df_fct_lump_post_covid), xcol = "longitude", ycol = "latitude", zcol = "fct_lump", crs = 4269, grid = FALSE, alpha.regions = 0.1)

# takeaway: map is too full,  let's just view  since 2022-04

df |>
  mutate(fct_lump = fct_lump(f = df$violation_code, n = 9)) |>
  mutate(date = date(violation_date)) |>
  filter(date >= "2022-04-01") |>
  mapview(xcol = "longitude", ycol = "latitude", zcol = "fct_lump", crs = 4269, grid = FALSE, alpha.regions = 0.2)

# takeaway: better, but still not as clear as I'd like.


# Let's just view fct_lump==1111D1C for the previous year:
df |>
  mutate(fct_lump = fct_lump(f = df$violation_code, n = 9)) |>
  mutate(date = date(violation_date)) |>
  filter(date >= "2022-04-01") |>
  filter(fct_lump == "1111D1C") |>
  mapview(xcol = "longitude", ycol = "latitude", crs = 4269, grid = FALSE, alpha.regions = 0.2)

# takeaway: we have a better view of the major ticketing areas for 1111D1C: uws, ues (and their corresponding avenues up through Harlem), up and down 1st and 2nd ave, especialy in the east village, over the Wburg Bridge, up and down 4th and 5th aves in Brooklyn, Liberty Ave in Ozone park/ Richmond Hill, East side of prospect park on Bedford Ave, and Bensonhurst, bk.
```

# EDA: Daily Cyclists

## Plot: daily total cyclists over time

```{r message=FALSE }
ts_daily_total |>
  autoplot(daily_total_cyclists) +
  geom_smooth(method = "lm")


# takeaway: ridership did not change much pre or post pandemic. not even during lockdown, although possible hickup.
# However, ridership seems to be increasing in the colder months while remaining level in the warmer months.
# since the ridership is clearly cyclical, an average won't tell us as much as we like.  But we can still see an increase over time.
```

### Slope: Daily increase in number of cyclists

```{r message=FALSE }
lm = lm(ts_daily_total$daily_total_cyclists~ts_daily_total$violation_date)
lm


# 4.665 increase per day
```


## Plot: yearly trend in number of cyclists

```{r message=FALSE }
str(df_counts_raw)

df_counts_raw |> 
  mutate(date = mdy_hms(date)) |> 
  group_by(date=year(date)) |> 
  summarise(yearly = sum(counts)) |> 
  ggplot(aes(x=date, y=yearly))+
  geom_line()
  
# potential issues;  fewer bike counters earlier on.
```


## Plot: daily total cyclists histogram

```{r}
ts_daily_total |>
  ggplot(aes(x = daily_total_cyclists)) +
  geom_histogram(bins = 80)
```

## Does ridership increase or decrease yearly?

```{r ridership-increase-yearly}
# leave out 2023 since we only have up to March

ts_daily_total |>
  index_by(year(violation_date)) |>
  summarize(across(c("daily_total_violations", "daily_total_cyclists"), ~ sum(.x, na.rm = TRUE))) |>
  rename(yearly_total_cyclists = daily_total_cyclists) |>
  rename(yearly_total_violations = daily_total_violations) |>
  rename(violation_date = "year(violation_date)") |>
  filter_index(. ~ "2022") |>
  autoplot(yearly_total_cyclists)

# Takeaway: Yes, it increases. slight dip in 2019 but clearly increasing
```

## Does ridership change throughout the year (seasonality)?

```{r}
# yearly seasonal plot
ts_daily_total |>
  gg_season(daily_total_cyclists)
# takeaway - it's roughly the same yearly cycle per year.  increase in ridership from May-Oct, decrease Nov-Apr

# same as above but monthly totals, looks cleaner:
ts_monthly_total |>
  gg_season(monthly_total_cyclists)
# takeaway - dip in April 2020 during covid lockdown, but not much less than before.
```


```{r yearly-ridership-trends-by-month}
# looking at it by month:
ts_monthly_total |>
  gg_subseries(monthly_total_cyclists)
# takeaways:
## seasonality is a little clearer.  monthly difference is clearer.
## 2023 is turning out to be noticeably more riders than previous years.


# Ridership changes over time takeways:
## Ridership is increasing.
## Clear yearly seasonality, with May-Oct being the busiest, and Nov-Apr being less busy.
## Dec, Jan, Feb have all been increaseing, especially post-pandemic
```

## Daily total cyclists decomposition

```{r daily-total-cyclists-decomp, message=FALSE, warning=FALSE }
# classical decomp doesnt handle multi seasonality too well
ts_daily_total |>
  #  filter(!is.na(daily_total_cyclists)) |>
  #  fill_gaps() |>
  model(classical_decomposition(daily_total_cyclists, type = "additive")) |>
  components() |>
  autoplot()


# STL - best so far
ts_daily_total |>
  model(
    STL(daily_total_cyclists ~ trend(window = 365) +
      season(period = "year") + season(period = "1 month"), )
  ) |>
  components() |>
  autoplot()

# what about moving average for trend?  it ok.  I think stl is best.
ts_daily_total |>
  mutate(`5-MA` = slider::slide_dbl(daily_total_cyclists, mean, .before = 90, .after = 90, .complete = TRUE)) |>
  autoplot(daily_total_cyclists) +
  geom_line(aes(y = `5-MA`), colour = "#D55E00")

# what about just a regular regression line
ts_daily_total |>
  autoplot(daily_total_cyclists) +
  stat_smooth(method = "lm")
```

# EDA: Daily Violations

## Plot: daily total violations over time

```{r}
ts_daily_total |>
  autoplot(daily_total_violations)

# takeaway:  There were more violations before the pandemic.  During lockdown, very few.
```

## Plot: daily total violations historgram

```{r}
ts_daily_total |>
  ggplot(aes(x = daily_total_violations)) +
  geom_histogram(bins = 80)
```

## Are the yearly number of violations trending up or down?

```{r}
ts_daily_total |>
  # filter_index('2020'~.) |>
  index_by(year(violation_date)) |>
  summarize(across(c("daily_total_violations", "daily_total_cyclists"), ~ sum(.x, na.rm = TRUE))) |>
  rename(yearly_total_cyclists = daily_total_cyclists) |>
  rename(yearly_total_violations = daily_total_violations) |>
  rename(violation_date = "year(violation_date)") |>
  filter_index(. ~ "2022") |>
  autoplot(yearly_total_violations)


# takeaway: not reall, post-covid. It looks steady.  2020, even with lockdown, had more violations than 2021 and 2022, but less than 2019.

# monthly:  just cleaner graph of daily violations over time.  Post-covid looks steady.
ts_monthly_total |>
  autoplot(monthly_total_violations)
```

## Do number of violations change throughout the year (seasonal)?

```{r}
# just post-covid
ts_daily_total |>
  filter_index("2020-03" ~ .) |>
  gg_season(daily_total_violations)


# is it easier to see monthly?
ts_monthly_total |>
  filter_index("2020-03" ~ .) |>
  gg_season(monthly_total_violations)

# subseries plot
ts_monthly_total |>
  filter_index("2020-03" ~ .) |>
  gg_subseries(monthly_total_violations)

# takeaway - Hard to see any trends, but fewer violations in Nov/Dec/Jan.  Most in Sept Oct.  2021 was a steady year.
```

## Which month or months have the most violations?

```{r}
# from graph above, March and September, but August is catching up.
```


## As the number of riders increases, does the number of violations also increase?

```{r message=FALSE}
# utilizes corrr library

df |>
  mutate(violation_date = date(violation_date)) |>
  group_by(violation_date) |>
  mutate(daily_total_violations = sum(n())) |>
  select(daily_total_cyclists, daily_total_violations) |>
  correlate() |>
  kable()

# takeaawy cor: 0.2167395 So no, as the number of riders increases, the number of violations does not.
```

## Plot: daily violations vs. daily cylists

```{r}
ts_daily_total |>
  ggplot(aes(x = daily_total_violations, y = daily_total_cyclists)) +
  geom_point()
```

## Does this differ for pre-covid and post-lockdown?

### Plot: Pre-covid

```{r message = FALSE, warning=FALSE}
# correlation:  0.5026907
cor <- ts_daily_total |>
  filter_index(~"2020-04") |>
  select(daily_total_cyclists, daily_total_violations) |>
  correlate() |>
  slice(1) |>
  select(daily_total_violations) |>
  as.numeric()

# pre-covid
ts_daily_total |>
  filter_index(~"2020-04") |>
  ggplot(aes(x = daily_total_violations, y = daily_total_cyclists)) +
  geom_point() +
  geom_smooth(method = lm) +
  sm_statCorr(label_x = 250, label_y = 1000)
```

### Plot: Post-covid

```{r message=FALSE}
# devtools::install_github('smin95/smplot2', force = TRUE)
# library(smplot2)

# post-covid
ts_daily_total |>
  filter_index("2020-04" ~ .) |>
  ggplot(aes(x = daily_total_violations, y = daily_total_cyclists)) +
  geom_point() +
  geom_smooth(method = lm) +
  sm_statCorr(label_x = 120, label_y = 1000)

# correlation:  ~0.38
ts_daily_total |>
  filter_index("2020-04" ~ .) |>
  select(daily_total_cyclists, daily_total_violations) |>
  correlate() |>
  kable()

# ans: they differ a little more than all together.  pre-covid was a better indicator.
```

## Do largest violations (summed per day) change over time?

```{r message = FALSE}
# code test to lump all except 10 highest factors into 'other' category
df |>
  mutate(fct_lump = fct_lump(f = df$violation_code, n = 9)) |>
  count(fct_lump) |>
  arrange(desc(n))

# plot: daily biggest violation (1111D1C) over time, post covid
df |>
  mutate(fct_lump = fct_lump(f = df$violation_code, n = 9)) |>
  filter(fct_lump == "1111D1C") |>
  mutate(date = date(violation_date)) |>
  filter(date >= "2020-04-01") |>
  summarize(
    sum = sum(n()),
    .by = c(date, fct_lump)
  ) |>
  ggplot(aes(x = date, y = sum)) +
  geom_line()


# takeaway:  No.  not much different than general daily violations plot.  lower amount around Dec/Jan, otherwise fairly steady.
```

## To Do: Did the type of violations change after covid?

```{r}
```

## To do: Can we predict ridership?

```{r}
```

## To do: Can we predict daily violations?

```{r}

```

#### scratchpad

```{r include=FALSE}
str(df)

# plot shows that ebikes and escooters didnt have their own categories until sometime in mid 2022. before that, everything was under 'bikes'
df |>
  ggplot(aes(x = violation_date, y = city_nm, col = veh_category)) +
  geom_jitter()

# nuthin
df |>
  ggplot(aes(x = violation_date, y = city_nm, col = violation_code)) +
  geom_jitter()

# violations per month
df |>
  group_by(yearmonth = yearmonth(violation_date)) |>
  summarize(total_violations = sum(n())) |>
  ggplot(aes(x = yearmonth, y = total_violations)) +
  geom_line()


# violations per borough per year
df |>
  group_by(year = yearmonth(violation_date), city_nm) |>
  summarize(total_violations = sum(n())) |>
  ggplot(aes(x = year, y = total_violations, col = city_nm)) +
  geom_line()


# cyclist counters per borough:
# library(forcats)
# df_bicycle_counters_boroughs |>
#  ggplot(aes(x = fct_infreq(Borough))) +
#  geom_bar() +
#  labs(x = "Borough", y = "Cyclist Counters")
```

```{r}

```
