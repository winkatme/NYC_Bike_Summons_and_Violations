---
title: "R Notebook"
output:
  html_document: 
    toc: yes
---


```{r message=FALSE}
library(knitr)
library(fpp3)
library(readxl)
library(httr)
library(glue)
```


# Import, Merge, and Clean Data

## Violation Codes data
### Import violations xlsx
```{r}
# import Code Violations xlsx
# source:  https://dmv.ny.gov/e-data/violationcodes.xlsx
# library(readxl)
# library(httr)

path = 'https://dmv.ny.gov/e-data/violationcodes.xlsx'

GET(path, write_disk(tf <- tempfile(fileext = ".xlsx")))
violations <- read_xlsx(tf, sheet=1)

violations <- violations %>% 
  rename('VIOLATION_CODE'='ADJ Code') %>% 
  select(c('VIOLATION_CODE', 'DESCRIPTION'))


```


### Clean violations codes
```{r}
# Remove duplicates

# IOLATION_CODE duplicates found: (1110A and 1151A)
# This step proved to be necessary, as merging the two documents would duplicate the number of rows of any violation code in df to match any duplicates in violations.  This caused the # of rows of df to be over 200,000, when it should have remained the same (184770)

violations %>% 
  count(VIOLATION_CODE) %>% 
  arrange(desc(n))

# view descriptions for 1110A
violations %>% 
  filter(VIOLATION_CODE=='1110A')
# DISOBEYED TRAFFIC DEVICE
# DISOBEYED TRAFFIC DEVICE - PAVEMENT MARKINGS
# we will change all to the second, longer description

# view descriptions for 1151A
violations %>% 
  filter(VIOLATION_CODE=='1151A')
# FAILED TO YIELD RIGHT-OF-WAY TO PEDESTRIAN IN CROSSWALK
# FAILED TO YIELD RIGHT-OF-WAY TO PEDESTRIAN ON SIDEWALK
# We will change all to read: 
# FAILED TO YIELD RIGHT-OF-WAY TO PEDESTRIAN ON SIDEWALK OR CROSSWALK


# Remove duplicates of violation codes
# and manually merge descriptions for duplicate violation_Codes

violations_no_dupes<-violations %>% 
  distinct(VIOLATION_CODE, .keep_all=TRUE) %>% 
  mutate(DESCRIPTION = case_when(VIOLATION_CODE=='1151A' ~ "FAILED TO YIELD RIGHT-OF-WAY TO PEDESTRIAN ON SIDEWALK OR CROSSWALK", TRUE ~ DESCRIPTION)) %>% 
  mutate(DESCRIPTION = case_when(VIOLATION_CODE=='1110A' ~ "DISOBEYED TRAFFIC DEVICE - PAVEMENT MARKINGS", TRUE ~ DESCRIPTION))
  
# OPTIONAL double-check no dupes
# violations_no_dupes %>%   
#   count(VIOLATION_CODE) %>% 
#   distinct(n)

# OPTIONAL double-check that 1110A and 1151A read what they are supposed to
# violations_no_dupes %>% 
#   filter(VIOLATION_CODE=='1151A'|VIOLATION_CODE=='1110A')


dim(violations_no_dupes)
```


## NYPD Summons data
### Import Year to Date NYPD Summons csv  
```{r}
# only run once

# import NYPD Summons csv
# source: https://data.cityofnewyork.us/Public-Safety/NYPD-B-Summons-Year-to-Date-/57p3-pdcj

df <- read.csv('NYPD_B_Summons__Year_to_Date_.csv')

# Remove unneeded columns.  update column types as needed
# CHG_LAW_CD - can be removed.  Just determines if it was ny state or local nyc law
# JURIS_CD - can be removed.  no info in metadata.  only one distinct value.
# VIOLATION_TIME - redundant
### to delete ### LAW_CODE_ON_TICKET - can probably be removed.  most likely redundant with VIOLATION_CODE
### to delete ### RPT_OWNING_CMD - precinct where reported. change this from integer to factor, since it acts similar to a zip code.

df<-df %>% 
  mutate(VIOLATION_CODE = as.factor(VIOLATION_CODE)) %>%
  mutate(VEH_CATEGORY = as.factor(VEH_CATEGORY)) %>% 
  mutate(CITY_NM = as.factor(CITY_NM)) %>% 
  mutate(RPT_OWNING_CMD = as.factor(RPT_OWNING_CMD)) %>% 
  mutate(VIOLATION_DATE = mdy(VIOLATION_DATE)+hms(VIOLATION_TIME)) %>% 
  select(-c(CHG_LAW_CD, VIOLATION_TIME, JURIS_CD)) %>% 
  rename('Location' = 'Location.Point')

#View(df)
str(df)
```

### Import historic summons data
```{r}
# https://data.cityofnewyork.us/Public-Safety/NYPD-B-Summons-Historic-/bme5-7ty4

path = 'https://www.dropbox.com/s/9pikbkygm7ywq2h/NYPD_B_Summons__Historic_.csv?dl=1'
df_historic <- read.csv(path)

df_historic<-df_historic %>% 
  mutate(VIOLATION_CODE = as.factor(VIOLATION_CODE)) %>%
  mutate(VEH_CATEGORY = as.factor(VEH_CATEGORY)) %>% 
  mutate(CITY_NM = as.factor(CITY_NM)) %>% 
  mutate(RPT_OWNING_CMD = as.factor(RPT_OWNING_CMD)) %>% 
  mutate(VIOLATION_DATE = mdy(VIOLATION_DATE)+hms(VIOLATION_TIME)) %>% 
  select(-c(CHG_LAW_CD, VIOLATION_TIME, JURIS_CD))  %>% 
  rename('Location' = 'location')

str(df_historic)
```


### Merge historic data with year to date data
```{r}
df_merged<-merge(df_historic, df, all.x = TRUE, all.y = TRUE)

# for whatever reason, violation_code was not saved as a factor when merged
df_merged<-df_merged %>% 
  mutate(VIOLATION_CODE = as.factor(VIOLATION_CODE))

str(df_merged)
#length(unique(df_merged$VIOLATION_CODE))

```

### Merge Summons data with with Violations data by violation code
```{r}
# matches violation description with violation code

df_merged<-df_merged %>% 
  left_join(x=df_merged, y=violations_no_dupes, by='VIOLATION_CODE') 

df_merged<-df_merged %>% 
  mutate(VIOLATION_CODE = as.factor(VIOLATION_CODE)) 
  

# OPTIONAL - double check values for code 1110A
#df %>% 
#   filter(VIOLATION_CODE=='1110A')

str(df_merged)
tail(df_merged)
```

### Clean merged data
```{r}
# convert to tsibble





# attempt to find missing dates

# To Double Check: possibly missing dec 31 2018 and dec 31 2019.  

# source: https://stackoverflow.com/questions/50724137/find-missing-days-in-r-date-sequence
date_range <- seq(min(date(df_merged$VIOLATION_DATE)), max(date(df_merged$VIOLATION_DATE)), by = 1) 

date_range[!date_range %in% date(df_merged$VIOLATION_DATE)] 

length(unique(date(df_merged$VIOLATION_DATE)))

max(date(df_merged$VIOLATION_DATE))-min(date(df_merged$VIOLATION_DATE))




```



## Count Data
### Import total rider counts
```{r}
#https://data.cityofnewyork.us/Transportation/Bicycle-Counts/uczf-rk3c

path2 = 'https://www.dropbox.com/s/oaklaldm8td9wem/Bicycle_Counts.csv?dl=1'
df_counts <- read.csv(path2)
 
df_counts<-df_counts %>% 
  mutate(date = mdy_hms(date))

head(df_counts)
str(df_counts)

```


### Create daily and weekly rider total columns
```{r}
# graph per-day counts
df_counts %>% 
  mutate(date = date(date)) %>% 
  group_by(date) %>% 
  summarize(per_day_counts = sum(counts)) %>% 
  #View()
  as_tsibble(index=date) %>% 
  autoplot()

date(df_counts$date[1])

# graph per-week counts
df_counts %>% 
  mutate(date = yearweek(date)) %>% 
  group_by(date) %>% 
  summarize(per_week_counts = sum(counts)) %>% 
  #View()
  as_tsibble(index=date) %>% 
  autoplot()

# create new columns for daily and weekly totals
df_counts<-df_counts %>% 
  group_by(date(date)) %>% 
  mutate(day_total = sum(counts)) %>% 
  ungroup %>%
  group_by(yearweek(date)) %>% 
  mutate(week_total = sum(counts)) %>% 
  ungroup %>% 
  arrange(date) %>% 
  select(-c('date(date)', 'yearweek(date)'))

str(df_counts)

```




## Merge summons data with total rider data
```{r}
str(df_counts)
str(df_merged)


# create 'date' column of just ymd (no hms) in df_counts to merge on
df_counts<-df_counts %>% 
  mutate(date=date(date)) %>% 
  select(-c(countid, id, status))
  

# match date column with equal one in df_merged.  Just choose bikes, as the count data is just for bikes.  Also makes merging go quicker.
df_bike_summons <- df_merged %>%
  filter(VEH_CATEGORY=='BIKE' | VEH_CATEGORY=='EBIKE' | VEH_CATEGORY=='ESCOOTER') %>% 
  mutate(date=date(VIOLATION_DATE)) %>% 
  left_join(y=df_counts, by='date', multiple='first') %>% 
  select(-c('counts', 'date')) %>% 
  arrange(VIOLATION_DATE)

# optional: write to csv
# file is approx 25mb. That exceeds limit for uploading via browser, but it is able to upload to git via push
#install.packages("glue")
todays_date <- Sys.Date()
path_name<-glue('df_bike_summons_{todays_date}.csv')
write.csv(df_bike_summons, path_name, row.names=FALSE)

path_name



head(df_bike_summons)

df_daily_total_summons <-df_bike_summons %>% 
  group_by(date(VIOLATION_DATE)) %>% 
  summarize(daily_total = sum(n()))


df_daily_total_summons %>% 
  as_tsibble() %>% 
  autoplot()

?as.irts

# to ts?

?as_tsibble

ts_summons <- df_bike_summons %>%
  mutate(VIOLATION_DATE=date(VIOLATION_DATE)) %>% 
  as_tsibble(index=VIOLATION_DATE, key=EVNT_KEY)

str(ts_summons)
interval(ts_summons)

ts_summons %>% 
  filter_index("2023") %>% 
  autoplot(day_total, period='week')


df_bike_summons %>% 
  ggplot(aes(x=VIOLATION_DATE, y=day_total))+
  geom_line()

```


# EDA
```{r}
# EDA

# distinct vehicle categories (8 total)
df %>% 
  distinct(VEH_CATEGORY)



# how many separate violations, and their counts? (ans: 82)
df_bike %>% 
  group_by(VIOLATION_CODE) %>% 
  count %>% 
  arrange(desc(n)) %>% 
  ungroup() %>% 
  head()



# date range
#ts_bike<-df_bike %>% 
#  mutate(VIOLATION_DATE = mdy(VIOLATION_DATE)) %>% 
#  as_tsibble(key = EVNT_KEY)

#str(ts_bike)
```

