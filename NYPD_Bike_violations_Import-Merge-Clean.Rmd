---
title: "R Notebook"
output:
  html_document: 
    toc: yes
---


```{r message=FALSE}
library(knitr)
library(fpp3)
library(readxl)
library(httr)
library(glue)
```


# Import, Merge, and Clean Data

## Violation Codes data
### Import violations xlsx
```{r}
# import Code Violations xlsx
# source:  https://dmv.ny.gov/e-data/violationcodes.xlsx
# library(readxl)
# library(httr)

path = 'https://dmv.ny.gov/e-data/violationcodes.xlsx'

GET(path, write_disk(tf <- tempfile(fileext = ".xlsx")))
violations <- read_xlsx(tf, sheet=1)

violations <- violations %>% 
  rename('VIOLATION_CODE'='ADJ Code') %>% 
  select(c('VIOLATION_CODE', 'DESCRIPTION'))


```


### Clean violations codes
```{r}
# Remove duplicates

# IOLATION_CODE duplicates found: (1110A and 1151A)
# This step proved to be necessary, as merging the two documents would duplicate the number of rows of any violation code in df to match any duplicates in violations.  This caused the # of rows of df to be over 200,000, when it should have remained the same (184770)

violations %>% 
  count(VIOLATION_CODE) %>% 
  arrange(desc(n))

# view descriptions for 1110A
violations %>% 
  filter(VIOLATION_CODE=='1110A')
# DISOBEYED TRAFFIC DEVICE
# DISOBEYED TRAFFIC DEVICE - PAVEMENT MARKINGS
# we will change all to the second, longer description

# view descriptions for 1151A
violations %>% 
  filter(VIOLATION_CODE=='1151A')
# FAILED TO YIELD RIGHT-OF-WAY TO PEDESTRIAN IN CROSSWALK
# FAILED TO YIELD RIGHT-OF-WAY TO PEDESTRIAN ON SIDEWALK
# We will change all to read: 
# FAILED TO YIELD RIGHT-OF-WAY TO PEDESTRIAN ON SIDEWALK OR CROSSWALK


# Remove duplicates of violation codes
# and manually merge descriptions for duplicate violation_Codes

violations_no_dupes<-violations %>% 
  distinct(VIOLATION_CODE, .keep_all=TRUE) %>% 
  mutate(DESCRIPTION = case_when(VIOLATION_CODE=='1151A' ~ "FAILED TO YIELD RIGHT-OF-WAY TO PEDESTRIAN ON SIDEWALK OR CROSSWALK", TRUE ~ DESCRIPTION)) %>% 
  mutate(DESCRIPTION = case_when(VIOLATION_CODE=='1110A' ~ "DISOBEYED TRAFFIC DEVICE - PAVEMENT MARKINGS", TRUE ~ DESCRIPTION))
  
# OPTIONAL double-check no dupes
# violations_no_dupes %>%   
#   count(VIOLATION_CODE) %>% 
#   distinct(n)

# OPTIONAL double-check that 1110A and 1151A read what they are supposed to
# violations_no_dupes %>% 
#   filter(VIOLATION_CODE=='1151A'|VIOLATION_CODE=='1110A')


dim(violations_no_dupes)
View(violations_no_dupes)
```


## NYPD Summons data
### Import Year to Date NYPD Summons csv  
```{r}
# only run once

# import NYPD Summons csv
# source: https://data.cityofnewyork.us/Public-Safety/NYPD-B-Summons-Year-to-Date-/57p3-pdcj

df <- read.csv('NYPD_B_Summons__Year_to_Date_.csv')

# Remove unneeded columns.  update column types as needed
# CHG_LAW_CD - can be removed.  Just determines if it was ny state or local nyc law
# JURIS_CD - can be removed.  no info in metadata.  only one distinct value.
# VIOLATION_TIME - redundant
### to delete ### LAW_CODE_ON_TICKET - can probably be removed.  most likely redundant with VIOLATION_CODE
### to delete ### RPT_OWNING_CMD - precinct where reported. change this from integer to factor, since it acts similar to a zip code.

df<-df %>% 
  mutate(VIOLATION_CODE = as.factor(VIOLATION_CODE)) %>%
  mutate(VEH_CATEGORY = as.factor(VEH_CATEGORY)) %>% 
  mutate(CITY_NM = as.factor(CITY_NM)) %>% 
  mutate(RPT_OWNING_CMD = as.factor(RPT_OWNING_CMD)) %>% 
  mutate(VIOLATION_DATE = mdy(VIOLATION_DATE)+hms(VIOLATION_TIME)) %>% 
  select(-c(CHG_LAW_CD, VIOLATION_TIME, JURIS_CD)) %>% 
  rename('Location' = 'Location.Point')

#View(df)
str(df)
```

### Import historic summons data
```{r}
# https://data.cityofnewyork.us/Public-Safety/NYPD-B-Summons-Historic-/bme5-7ty4

path = 'https://www.dropbox.com/s/9pikbkygm7ywq2h/NYPD_B_Summons__Historic_.csv?dl=1'
df_historic <- read.csv(path)

df_historic<-df_historic %>% 
  mutate(VIOLATION_CODE = as.factor(VIOLATION_CODE)) %>%
  mutate(VEH_CATEGORY = as.factor(VEH_CATEGORY)) %>% 
  mutate(CITY_NM = as.factor(CITY_NM)) %>% 
  mutate(RPT_OWNING_CMD = as.factor(RPT_OWNING_CMD)) %>% 
  mutate(VIOLATION_DATE = mdy(VIOLATION_DATE)+hms(VIOLATION_TIME)) %>% 
  select(-c(CHG_LAW_CD, VIOLATION_TIME, JURIS_CD))  %>% 
  rename('Location' = 'location')

str(df_historic)
```


### Merge historic data with year to date data
```{r}
df_merged<-merge(df_historic, df, all.x = TRUE, all.y = TRUE)

# for whatever reason, violation_code was not saved as a factor when merged
df_merged<-df_merged %>% 
  mutate(VIOLATION_CODE = as.factor(VIOLATION_CODE))

str(df_merged)
#length(unique(df_merged$VIOLATION_CODE))

```

### Merge Summons data with with Violations data by violation code
```{r}
# matches violation description with violation code

df_merged<-df_merged %>% 
  left_join(x=df_merged, y=violations_no_dupes, by='VIOLATION_CODE') 

df_merged<-df_merged %>% 
  mutate(VIOLATION_CODE = as.factor(VIOLATION_CODE)) 
  

# OPTIONAL - double check values for code 1110A
#df %>% 
#   filter(VIOLATION_CODE=='1110A')

str(df_merged)
tail(df_merged)
```

### Clean merged data
```{r}
# convert to tsibble





# attempt to find missing dates

# To Double Check: possibly missing dec 31 2018 and dec 31 2019.  

# source: https://stackoverflow.com/questions/50724137/find-missing-days-in-r-date-sequence
date_range <- seq(min(date(df_merged$VIOLATION_DATE)), max(date(df_merged$VIOLATION_DATE)), by = 1) 

date_range[!date_range %in% date(df_merged$VIOLATION_DATE)] 

length(unique(date(df_merged$VIOLATION_DATE)))

max(date(df_merged$VIOLATION_DATE))-min(date(df_merged$VIOLATION_DATE))




```



## Count Data
### Import total rider counts
```{r}
#https://data.cityofnewyork.us/Transportation/Bicycle-Counts/uczf-rk3c

path2 = 'https://www.dropbox.com/s/oaklaldm8td9wem/Bicycle_Counts.csv?dl=1'
df_counts <- read.csv(path2)
 
df_counts<-df_counts %>% 
  mutate(date = mdy_hms(date))

head(df_counts)
str(df_counts)

```


### Create daily and weekly rider total columns
```{r}
# graph per-day counts
df_counts %>% 
  mutate(date = date(date)) %>% 
  group_by(date) %>% 
  summarize(per_day_counts = sum(counts)) %>% 
  #View()
  as_tsibble(index=date) %>% 
  autoplot()

date(df_counts$date[1])

# graph per-week counts
df_counts %>% 
  mutate(date = yearweek(date)) %>% 
  group_by(date) %>% 
  summarize(per_week_counts = sum(counts)) %>% 
  #View()
  as_tsibble(index=date) %>% 
  autoplot()

# create new columns for daily and weekly totals
df_counts<-df_counts %>% 
  group_by(date(date)) %>% 
  mutate(day_total = sum(counts)) %>% 
  ungroup %>%
  group_by(yearweek(date)) %>% 
  mutate(week_total = sum(counts)) %>% 
  ungroup %>% 
  arrange(date) %>% 
  select(-c('date(date)', 'yearweek(date)'))

str(df_counts)

```




## Merge summons data with total rider data
```{r}
str(df_counts)
str(df_merged)


# create 'date' column of just ymd (no hms) in df_counts to merge on
df_counts<-df_counts %>% 
  mutate(date=date(date)) %>% 
  select(-c(countid, id, status))
  

# match date column with equal one in df_merged.  Just choose bikes, as the count data is just for bikes.  Also makes merging go quicker.
df_bike_summons <- df_merged %>%
  filter(VEH_CATEGORY=='BIKE' | VEH_CATEGORY=='EBIKE' | VEH_CATEGORY=='ESCOOTER') %>% 
  mutate(date=date(VIOLATION_DATE)) %>% 
  left_join(y=df_counts, by='date', multiple='first') %>% 
  select(-c('counts', 'date')) %>% 
  rename('daily_total_cyclists' = 'day_total') %>% 
  rename('weekly_total_cyclists' = 'week_total') %>% 
  arrange(VIOLATION_DATE)

head(df_bike_summons)
```
### Clean n/a values in description
```{r}
# check to see which Violation codes correspond to empty description cells

df_bike_summons %>% 
  filter(is.na(DESCRIPTION)) %>% 
  distinct(VIOLATION_CODE)

# There were 4 distinct Violation codes with no description:
# 37524A (NOTE: after adjusting this value, this is the 5th most common violation code) - since 37524 is UNLAWFUL USE OF TV RECEIVING SET and 37524AB is OPER BICYCLE WITH MORE 1 EARPHONE, I will take the liberty to change all of these to 37524AB.
# 4014 does not exist, but 4014B is COMMERCIAL VEHICLE ON PARKWAY- NYC.  Change all to 4014B
# 4021 is associated with 4 different violation codes:  4021A - NO LICENSE PLATE OR SINGLE LICENSE PLATE, 4021B1 - DIRTY PLATE OR PLATE COVERED BY GLASS OR PLASTIC, 4021B2 - PLATE KNOWINGLY COVERED WITH INTENT TO OBSCURE, 4021B3 - PLATE OBSCURED BY VEHICLE OR ANYTHING CARRIED THERON.  Since these are all related to license plates, I will change these all to 4021A
# 22653 - this was closest to two values, 22651 - EQUIPMENT VIOLATION LIMITED USE VEHICLE and 22651M - MISCELLANEOUS EQUIPMENT VIOLATION - LIMITED USE MOTORCYCLE.  Since all 18 of the 22653 violations were either e-bike or escooter, I will change all of these to 22651M

#df_bike_summons %>% 
#  filter(VIOLATION_CODE=='22653')


# change all violation codes to decided on values
df_bike_summons<-df_bike_summons %>% 
  mutate(VIOLATION_CODE = replace(VIOLATION_CODE, VIOLATION_CODE == '37524A', '37524AB')) %>%
  mutate(VIOLATION_CODE = replace(VIOLATION_CODE, VIOLATION_CODE == '4014', '4014B')) %>%
  mutate(VIOLATION_CODE = replace(VIOLATION_CODE, VIOLATION_CODE == '4021', '4021A')) %>%
  mutate(VIOLATION_CODE = replace(VIOLATION_CODE, VIOLATION_CODE == '22653', '22651M')) 

# change all descriptions baseed on new violation code values
df_bike_summons$DESCRIPTION[df_bike_summons$VIOLATION_CODE=='37524AB'] <- 'OPER BICYCLE WITH MORE 1 EARPHONE'
df_bike_summons$DESCRIPTION[df_bike_summons$VIOLATION_CODE=='4014B'] <- 'COMMERCIAL VEHICLE ON PARKWAY- NYC'
df_bike_summons$DESCRIPTION[df_bike_summons$VIOLATION_CODE=='4021A'] <- 'NO LICENSE PLATE OR SINGLE LICENSE PLATE'
df_bike_summons$DESCRIPTION[df_bike_summons$VIOLATION_CODE=='22651M'] <- 'MISCELLANEOUS EQUIPMENT VIOLATION - LIMITED USE MOTORCYCLE'


# check for na's
df_bike_summons %>% 
  filter(is.na(daily_total_cyclists))

# check factors for na's
df_bike_summons %>% 
  distinct(CITY_NM)

# CITY_NM has empty values that don't say NA.  Let's make them say NA
df_bike_summons$CITY_NM <- as.character(df_bike_summons$CITY_NM)
df_bike_summons$CITY_NM[df_bike_summons$CITY_NM==""] <- NA
df_bike_summons$CITY_NM <- as.factor(df_bike_summons$CITY_NM)

# how many na values now?
df_bike_summons %>% 
  group_by(CITY_NM) %>% 
  summarize(sum = sum(n()))

# To do:  figure out what to do with NA values
# To do: figure out if 'New York' values can be merged with 'Manhattan'

```



### Optional - save csv
```{r}
# optional: write to csv
# file is approx 25mb. That exceeds limit for uploading via browser, but it is able to upload to git via push
#install.packages("glue")
#todays_date <- Sys.Date()
#path_name<-glue('df_bike_summons_{todays_date}.csv')
#write.csv(df_bike_summons, path_name, row.names=FALSE)
```



# EDA
```{r}
# EDA

# distinct vehicle categories (8 total)
df %>% 
  distinct(VEH_CATEGORY)



# how many separate violations, and their counts? (ans: 82)
df_bike %>% 
  group_by(VIOLATION_CODE) %>% 
  count %>% 
  arrange(desc(n)) %>% 
  ungroup() %>% 
  head()



# date range
#ts_bike<-df_bike %>% 
#  mutate(VIOLATION_DATE = mdy(VIOLATION_DATE)) %>% 
#  as_tsibble(key = EVNT_KEY)

#str(ts_bike)
```

