---
title: "R Notebook"
output:
  html_document:
    df_print: paged
    keep_md: yes
---


```{r libraries, message=FALSE, warning=FALSE, include=FALSE}
library(knitr)
library(tidyverse)
library(fpp3)
#install.packages("urca")
library(urca)
library(kableExtra)
library(corrr)
```

# Import daily and monthly tsibbles

```{r}
# import bike violations

df_bike_violations <- readr::read_csv("Data/Processed/df_bike_violations_2023-09-16.csv")

df_bike_violations <- df_bike_violations |>
  mutate(violation_code = as.factor(violation_code)) |>
  mutate(veh_category = as.factor(veh_category)) |>
  mutate(city_nm = as.factor(city_nm)) |>
  mutate(rpt_owning_cmd = as.factor(rpt_owning_cmd)) |>
  mutate(violation_date = as.POSIXct(violation_date))

# creat daily tsibble

# import and clean df_counts:
path3 <- "https://www.dropbox.com/s/nffkpwuz1u6kd5t/df_counts.csv?dl=1"
df_counts_dl <- readr::read_csv(path3)


df_counts <-df_counts_dl |> 
  group_by(date(date)) |>
  mutate(daily_total = sum(counts)) |>
  ungroup() |>
  group_by(yearweek(date)) |>
  mutate(weekly_total = sum(counts)) |>
  ungroup() |>
  arrange(date) |>
  select(!c("date(date)", "yearweek(date)", countid, status))


# create the daily counts tsibble
ts_daily_total <- df_bike_violations |> 
  group_by(violation_date = as_date(violation_date)) |> 
  summarise(daily_total_violations = n()) |> 
  as_tsibble(index = violation_date) |> 
  fill_gaps() |> 
  mutate(date = violation_date) |> 
  left_join(y = df_counts, by = "date", multiple = "any") |> 
  rename(daily_total_cyclists = daily_total)|> 
  select(-c(date, id, counts, weekly_total))

ts_daily_total |> 
  count_gaps()
```

create a monthly data tsibble from cleaned daily tsibble

```{r}

ts_monthly_total <- ts_daily_total |> 
  index_by(year_month = ~ yearmonth(.)) |> 
  summarise(monthly_total_cyclists = sum(daily_total_cyclists),
            monthly_total_violations = sum(daily_total_violations, na.rm = TRUE)) |> 
  rename(violation_date = year_month)


ts_yearly_total <- ts_daily_total |> 
  index_by(year = ~ year(.)) |> 
  summarise(yearly_total_cyclists = sum(daily_total_cyclists),
            yearly_total_violations = sum(daily_total_violations, na.rm = TRUE)) |> 
  rename(violation_date = year)
```


# Forecasting: Monthly total riders

Let's see how the daily totals look

```{r}
ts_daily_total |> 
  autoplot(daily_total_cyclists)
```

Pretty messy.  The monthly totals look easier to read, so let's use those:

```{r}
ts_monthly_total |> 
  autoplot(monthly_total_cyclists)
```


## Train and test sets for monthly data

Training set is through May of 2022.  Test set is from June 2022 through June 2023.

```{r}
set.seed(99)

train_monthly<-ts_monthly_total |> select(monthly_total_cyclists) |> filter_index(~"2022-05")
test_monthly<-ts_monthly_total |> select(monthly_total_cyclists) |> filter_index("2022-06"~.)

(range(train_monthly$violation_date))
(range(test_monthly$violation_date))


train_daily<-ts_daily_total |> select(daily_total_cyclists) |> filter_index(~"2022-05")
test_daily<-ts_daily_total |> select(daily_total_cyclists) |> filter_index("2022-06"~.)

(range(train_daily$violation_date))
(range(test_daily$violation_date))
```

## Seasonal Naive forecast on monthly totals

```{r}
ts_monthly_snaive_mod <- ts_monthly_total |> 
  model(model = NAIVE(monthly_total_cyclists ~ lag(12)))

ts_fc <- ts_monthly_snaive_mod|> forecast(h = "2 years")

ts_fc |> 
  autoplot(ts_monthly_total)
```


### Seasonal naive monthly residuals

lag = 12

```{r, warning=FALSE}
train_snaive_mod <- train_monthly |> 
  model(model = NAIVE(monthly_total_cyclists ~ lag(12)))

mean(augment(train_snaive_mod)$.resid, na.rm=TRUE)  # 70130.59 (changes each time?)

gg_tsresiduals(train_snaive_mod)
```

Tests to see if residuals differ from white noise:

```{r}
augment(train_snaive_mod) %>% features(.innov, box_pierce, lag = 12)
augment(train_snaive_mod) %>% features(.innov, ljung_box, lag = 12)
```

Takeaways: passes box_pierce, but fails ljung_box.  Resids don't seem normal.  

### Seasonal Naive RMSE

```{r}

fct <-train_monthly |> 
  model(model = NAIVE(monthly_total_cyclists ~ lag(12))) |> 
  forecast(test_monthly)

(RMSE_seasonal_naive_monthly <-accuracy(fct, ts_monthly_total)$RMSE)

```

RMSE 139936.1

### Visualize the Seasonal Naive forecast:

```{r message=FALSE, warning=FALSE}
autoplot(train_monthly) +
  autolayer(fct, PI = F, size=0.7)+
  autolayer(test_monthly)
```

Takeaway:  Errors can get extreme (less than 0 at one point). Does not take into account the trend of the data.  Let's compare to other methods.


## Seasonal Naive daily 

```{r}
ts_daily_snaive_mod <- ts_daily_total |> 
  model(model = NAIVE(daily_total_cyclists ~ lag(365)))


ts_daily_total |> 
  count_gaps()

ts_fc <- ts_daily_snaive_mod|> forecast(h = "1 year")

ts_fc |> 
  autoplot(ts_daily_total)
```

It's much more difficult to predict daily due to smaller period. Although it might be more accurate for forecast smaller time periods, like a single month, I would like to predict in yearly terms, so let's stick to monthly.


Since there is clear seasonality, let's try ETS

## ETS Forecast on monthly data (ETS_AAA)

Method chosen: Holt winters additive (AAA) (with seasonality)
Because the seasonal variations are roughly constant through the series.

```{r}
fit_ETS <- ts_monthly_total %>%
  model(ETS(monthly_total_cyclists ~ error("A") + trend("A") + season("A")))

fc <- fit_ETS |> forecast(h = "2 years")

fc |> 
  autoplot(ts_monthly_total)
```

How does it perform on the test set?

```{r}
fct <- train_monthly |> 
  model(ETS(monthly_total_cyclists ~ error("A") + trend("A") + season("A"))) |> 
  forecast(test_monthly)

(RMSE_ETS_AAA_monthly <-accuracy(fct, ts_monthly_total)$RMSE)
```

RMSE = 86248.05.  Better

### Visualize ETS_AAA

```{r plot-ets-aaa}
autoplot(train_monthly) +
  autolayer(fct, PI = F, size=0.7)+
  autolayer(test_monthly)
```


Maybe the trend was too strong.  I wonder if we can do damping

## ETS with trend damping (ETS_AAdA)

```{r}
fct_ETS_AAdA <- train_monthly |> 
  model(ETS(monthly_total_cyclists ~ error("A") + trend("Ad") + season("A"))) |> 
  forecast(test_monthly)

(RMSE_ETS_AAdA <-accuracy(fct_ETS_AAdA, ts_monthly_total)$RMSE)
```

RMSE: 94780.86

### Vusialize ETS with trend damping

```{r message=FALSE, warnings=FALSE}
autoplot(train_monthly) +
  autolayer(fct_ETS_AAdA, size=0.7)+
  autolayer(test_monthly)
```

Does it look different when we train it on all of the data and forecast 2 years?

```{r}
fit_ETS <- ts_monthly_total %>%
  model(ETS(monthly_total_cyclists ~ error("A") + trend("Ad") + season("A")))

fc <- fit_ETS |> forecast(h = "2 years")

fc |> 
  autoplot(ts_monthly_total)
```

Just by looking at it, the peak in the summer of 2024 doesn't reach as high.  It's a little more conservative of an estimation.  


## Auto-ETS (ETS_ANA)

What does the ETS command itself decide to be the best model for the training data?

```{r}
mod_Auto_ETS <-train_monthly |> 
  model(ETS(monthly_total_cyclists))

report(mod_Auto_ETS)
```

It has chosen a much different model, MNM.  Let's see how it does on the test data

```{r}
fct_ETS_MNM <- mod_Auto_ETS |> 
  forecast(test_monthly)


(RMSE_ETS_MNM <-accuracy(fct_ETS_MNM, ts_monthly_total)$RMSE)
```

The RMSE is 116723.8.  Not the best.  

How would an ARIMA model fare?

## Auto-ARIMA model 

Let's see what ARIMA model the auto-ARIMA chooses.

```{r}
mod_Auto_ARIMA <- train_monthly |> 
  model(ARIMA(monthly_total_cyclists)) 

report(mod_Auto_ARIMA)
```

'Auto-ARIMA' has chosen an ARIMA(1,0,0)(1,1,0)[12] w/ drift model for the train dataset.  Let's see how it scores on the test dataset

```{r}
fct_Auto_ARIMA <- mod_Auto_ARIMA |> 
  forecast(test_monthly)

(RMSE_ARIMA_100_110_12 <-accuracy(fct_Auto_ARIMA, ts_monthly_total)$RMSE)
```

114677.4.  Not nearly as good as out best ETS.

Let's see what it's forecast looks like:

```{r message=FALSE, warning=FALSE}
autoplot(train_monthly) +
  autolayer(fct_Auto_ARIMA, size=0.7)+
  autolayer(test_monthly)
```

# Model Summations

```{r}
cat('seasonal Naive:\t\t\t', RMSE_seasonal_naive_monthly, '\n', 
    'ETS_AAA:\t\t\t', RMSE_ETS_AAA_monthly, '\n',
    'ETS_AAdA:\t\t\t', RMSE_ETS_AAdA, '\n',
    'ETS_ANA:\t\t\t', RMSE_ETS_MNM, '\n',
    'ARIMA (1,0,0)(1,1,0)[12]\t', RMSE_ARIMA_100_110_12)

```

```{r table-forecasting-methods}
tests <- c('Seasonal Naive', 'ETS_AAA', 'ETS_AAdA', 'ETS_MNM',  'ARIMA (1,0,0)(1,1,0)[12]')
RMSE <- c(RMSE_seasonal_naive_monthly, RMSE_ETS_AAA_monthly, RMSE_ETS_AAdA, RMSE_ETS_MNM, RMSE_ARIMA_100_110_12)

df_forecasting <- data.frame(tests, RMSE)

df_forecasting |> 
  kable(caption = "Forecasts", col.names = linebreak(c('Forecasting Method', 'RMSE'), align = "l")) |> 
  kable_classic(full_width = F, html_font = "Cambria", position = "left")
```




##TS regression model

Correlation

```{r}
cor(ts_monthly_total$monthly_total_cyclists, ts_monthly_total$monthly_total_violations)
```

The correlation is very small 

Is there a linear relationship between monthly violations and total cyclists?

```{r}
ts_monthly_total |> 
  ggplot(aes(x=monthly_total_violations, y=monthly_total_cyclists))+
  geom_point()
```

Takeway:  it looks like there might be two separate groups here.  My guess is that the groups are pre-covid and post.  Let's just look at post covid:

Post covid cor:

```{r message=FALSE, warning=FALSE}
ts_monthly_total |> 
  filter_index('2020-04'~.) |> 
  select(monthly_total_violations, monthly_total_cyclists) |> 
  correlate()

```

The correlation is now 0.5053488  Much better.

Post covid plot:

```{r message=FALSE, warning=FALSE}
ts_monthly_total |> 
  filter_index('2020-04' ~.) |> 
  ggplot(aes(x=monthly_total_violations , y=monthly_total_cyclists))+
  geom_point()+
  geom_smooth(method = "lm", se = FALSE)
```

Looks better.  What if we color it by month?

```{r}
ts_monthly_total |> 
  filter_index('2020-04' ~.) |> 
  mutate(month=as.factor(month(violation_date))) |> 
  ggplot(aes(x=monthly_total_violations, y=monthly_total_cyclists, col=month))+
  geom_point()

```

Takeaway: Visually, the months do seem to cluster together.  

double-check: is that april that's  month number 4 in the green with the minimum violations?

```{r}
ts_monthly_total |> 
  filter_index('2020-04' ~.) |> 
  slice(which.min(monthly_total_violations))
```

Yes.  So we can safely assume that month 1 is Jan, 2 is Feb, etc.


### TS Reg model (post covid)

Without trend or season:

```{r}
ts_reg_mod1 <- ts_monthly_total |> 
  filter_index('2020-04' ~.) |> 
	model(TSLM(monthly_total_cyclists ~ monthly_total_violations))

report(ts_reg_mod1)
```


Terrible adjusted R-square (0.2353)

With slope and season:

```{r}
ts_reg_mod2 <- ts_monthly_total |> 
  filter_index('2020-04' ~.) |> 
	model(TSLM(monthly_total_cyclists ~ monthly_total_violations+ trend() + season()))

report(ts_reg_mod2)

```

Takeaway:  The adjusted R^2 is 0.8984, which is very good. June-Sept seems to have the highest beta values.  monthly total violations has a tiny beta value, by far.  This shows that seasonality has a larger impact on total cyclists than monthly total violations.


Is monthly total cyclists normally distributed?  

```{r}
shapiro.test(ts_monthly_total$monthly_total_cyclists) # no:  p-value = 0.0079

qqnorm(ts_monthly_total$monthly_total_cyclists)
```



Ans: NO


## To do: Can we foreast daily violations?


```{r}



```

# ETS_AAA (best model) evaluation

```{r plot-ets-aaa-resids, message=FALSE, warning=FALSE}
mod_ETS_AAA <- train_monthly %>%
  model(ETS(monthly_total_cyclists ~ error("A") + trend("A") + season("A")))

gg_tsresiduals(mod_ETS_AAA)+
  ggtitle('ETS AAA Residuals')
```

Takeaway: resids look normal enough.  possible autocorrelation. Tests:

```{r}
augment(mod_ETS_AAA) |> features(.innov, box_pierce, lag = 12)
augment(mod_ETS_AAA) |> features(.innov, ljung_box, lag = 12)
```

Both tests fail to reject null.  We may safely conclude that residuals are white noise.

```{r ets-aaa-shapiro-wilks}
shapiro.test(residuals(mod_ETS_AAA)$.resid)
```


Let's forecast through 2025

```{r plot-ets-aaa-fct-2025, message=FALSE, warning=FALSE}
fct_ETS_AAA <- train_monthly |> 
  model(ETS(monthly_total_cyclists ~ error("A") + trend("A") + season("A"))) |> 
  forecast(h=36)

ts_monthly_total |> 
  autoplot(monthly_total_cyclists) +
  #autoplot(ts_monthly_total$monthly_total_cyclists) +
  autolayer(fct_ETS_AAA, size=0.7)+
  autolayer(test_monthly)
```

```{r}
tidy(mod_ETS_AAA)
```



Takeaway:  This model seems to adequately increase the summer peaks while slowly increasing the winter lulls.  This fits our eda.  
